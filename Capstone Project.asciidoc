== Capstone Project - Car accident severity

== Business Understanding

Using the dataset for collisions, with a various host of attributes
being recorded, we would like to understand if any relationships occur
within the data that could lead to a reliable prediction of accident
severity; through building an appropriate model for the given dataset.

== Data Understanding

The dataset contains information on location type, collision type, types
of objects/people involved, weather/road conditions and collision
description, which are all potentially useful attributes to ascertain
any inter-relationships that could help predict accident severity.


+*In[1]:*+
[source, ipython3]
----
import matplotlib.pyplot as plt
import pandas as pd
import pylab as pl
import numpy as np
%matplotlib inline
----

== Notes

* Check for correlation between type of accident and severity
* Check for correlation between location and severity
* Check for correlation between location and type of accident
* Accident severity vs. time of day?
* Consider excluding data before a certain year? - to take into
consideration any changes that may have occured to various locations
* Since there’s only 2 severity categories, plot various attribute
values against mean severity


+*In[2]:*+
[source, ipython3]
----
import os
print(os.getcwd())
----


+*Out[2]:*+
----
/resources/labs/coursera/ML0101EN
----


+*In[3]:*+
[source, ipython3]
----
accidents = pd.read_csv("Data-Collisions_csv.csv")
accidents.head()
----


+*Out[3]:*+
----
/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (33) have mixed types.Specify dtype option on import or set low_memory=False.
  interactivity=interactivity, compiler=compiler, result=result)

[cols=",,,,,,,,,,,,,,,,,,,,,",options="header",]
|===
| |SEVERITYCODE |X |Y |OBJECTID |INCKEY |COLDETKEY |REPORTNO |STATUS
|ADDRTYPE |INTKEY |... |ROADCOND |LIGHTCOND |PEDROWNOTGRNT |SDOTCOLNUM
|SPEEDING |ST_COLCODE |ST_COLDESC |SEGLANEKEY |CROSSWALKKEY
|HITPARKEDCAR
|0 |2 |-122.323148 |47.703140 |1 |1307 |1307 |3502005 |Matched
|Intersection |37475.0 |... |Wet |Daylight |NaN |NaN |NaN |10 |Entering
at angle |0 |0 |N

|1 |1 |-122.347294 |47.647172 |2 |52200 |52200 |2607959 |Matched |Block
|NaN |... |Wet |Dark - Street Lights On |NaN |6354039.0 |NaN |11 |From
same direction - both going straight - bo... |0 |0 |N

|2 |1 |-122.334540 |47.607871 |3 |26700 |26700 |1482393 |Matched |Block
|NaN |... |Dry |Daylight |NaN |4323031.0 |NaN |32 |One parked--one
moving |0 |0 |N

|3 |1 |-122.334803 |47.604803 |4 |1144 |1144 |3503937 |Matched |Block
|NaN |... |Dry |Daylight |NaN |NaN |NaN |23 |From same direction - all
others |0 |0 |N

|4 |2 |-122.306426 |47.545739 |5 |17700 |17700 |1807429 |Matched
|Intersection |34387.0 |... |Wet |Daylight |NaN |4028032.0 |NaN |10
|Entering at angle |0 |0 |N
|===

5 rows × 38 columns
----


+*In[4]:*+
[source, ipython3]
----
accidents["LOCATION"].value_counts()
# Too many different locations to consider using this as a feature
----


+*Out[4]:*+
----BATTERY ST TUNNEL NB BETWEEN ALASKAN WY VI NB AND AURORA AVE N    276
BATTERY ST TUNNEL SB BETWEEN AURORA AVE N AND ALASKAN WY VI SB    271
N NORTHGATE WAY BETWEEN MERIDIAN AVE N AND CORLISS AVE N          265
AURORA AVE N BETWEEN N 117TH PL AND N 125TH ST                    254
6TH AVE AND JAMES ST                                              252
                                                                 ... 
S AUSTIN ST BETWEEN DEAD END AND 35TH AVE S                         1
NE 57TH ST BETWEEN 8TH AVE NE AND ROOSEVELT WAY NE                  1
34TH AVE S BETWEEN CLAREMONT PL S AND S DAKOTA ST                   1
34TH AVE BETWEEN E OLIVE ST AND E HOWELL ST                         1
6TH AVE S BETWEEN S BRADFORD ST AND S ANDOVER ST                    1
Name: LOCATION, Length: 24102, dtype: int64----


+*In[5]:*+
[source, ipython3]
----
accidents.describe(include="all")
----


+*Out[5]:*+
----
[cols=",,,,,,,,,,,,,,,,,,,,,",options="header",]
|===
| |SEVERITYCODE |X |Y |OBJECTID |INCKEY |COLDETKEY |REPORTNO |STATUS
|ADDRTYPE |INTKEY |... |ROADCOND |LIGHTCOND |PEDROWNOTGRNT |SDOTCOLNUM
|SPEEDING |ST_COLCODE |ST_COLDESC |SEGLANEKEY |CROSSWALKKEY
|HITPARKEDCAR
|count |194673.000000 |189339.000000 |189339.000000 |194673.000000
|194673.000000 |194673.000000 |194673 |194673 |192747 |65070.000000 |...
|189661 |189503 |4667 |1.149360e+05 |9333 |194655 |189769 |194673.000000
|1.946730e+05 |194673

|unique |NaN |NaN |NaN |NaN |NaN |NaN |194670 |2 |3 |NaN |... |9 |9 |1
|NaN |1 |115 |62 |NaN |NaN |2

|top |NaN |NaN |NaN |NaN |NaN |NaN |1782439 |Matched |Block |NaN |...
|Dry |Daylight |Y |NaN |Y |32 |One parked--one moving |NaN |NaN |N

|freq |NaN |NaN |NaN |NaN |NaN |NaN |2 |189786 |126926 |NaN |... |124510
|116137 |4667 |NaN |9333 |27612 |44421 |NaN |NaN |187457

|mean |1.298901 |-122.330518 |47.619543 |108479.364930 |141091.456350
|141298.811381 |NaN |NaN |NaN |37558.450576 |... |NaN |NaN |NaN
|7.972521e+06 |NaN |NaN |NaN |269.401114 |9.782452e+03 |NaN

|std |0.457778 |0.029976 |0.056157 |62649.722558 |86634.402737
|86986.542110 |NaN |NaN |NaN |51745.990273 |... |NaN |NaN |NaN
|2.553533e+06 |NaN |NaN |NaN |3315.776055 |7.226926e+04 |NaN

|min |1.000000 |-122.419091 |47.495573 |1.000000 |1001.000000
|1001.000000 |NaN |NaN |NaN |23807.000000 |... |NaN |NaN |NaN
|1.007024e+06 |NaN |NaN |NaN |0.000000 |0.000000e+00 |NaN

|25% |1.000000 |-122.348673 |47.575956 |54267.000000 |70383.000000
|70383.000000 |NaN |NaN |NaN |28667.000000 |... |NaN |NaN |NaN
|6.040015e+06 |NaN |NaN |NaN |0.000000 |0.000000e+00 |NaN

|50% |1.000000 |-122.330224 |47.615369 |106912.000000 |123363.000000
|123363.000000 |NaN |NaN |NaN |29973.000000 |... |NaN |NaN |NaN
|8.023022e+06 |NaN |NaN |NaN |0.000000 |0.000000e+00 |NaN

|75% |2.000000 |-122.311937 |47.663664 |162272.000000 |203319.000000
|203459.000000 |NaN |NaN |NaN |33973.000000 |... |NaN |NaN |NaN
|1.015501e+07 |NaN |NaN |NaN |0.000000 |0.000000e+00 |NaN

|max |2.000000 |-122.238949 |47.734142 |219547.000000 |331454.000000
|332954.000000 |NaN |NaN |NaN |757580.000000 |... |NaN |NaN |NaN
|1.307202e+07 |NaN |NaN |NaN |525241.000000 |5.239700e+06 |NaN
|===

11 rows × 38 columns
----


+*In[6]:*+
[source, ipython3]
----
severity_missing = accidents["SEVERITYCODE"].isnull()
severity_missing
----


+*Out[6]:*+
----0         False
1         False
2         False
3         False
4         False
          ...  
194668    False
194669    False
194670    False
194671    False
194672    False
Name: SEVERITYCODE, Length: 194673, dtype: bool----


+*In[7]:*+
[source, ipython3]
----
severity_missing.value_counts()
----


+*Out[7]:*+
----False    194673
Name: SEVERITYCODE, dtype: int64----


+*In[8]:*+
[source, ipython3]
----
# Extracting features which could be useful predictors and create a new dataframe
accidents_df = accidents[["SEVERITYCODE","ADDRTYPE","COLLISIONTYPE","PERSONCOUNT","PEDCOUNT","PEDCYLCOUNT","VEHCOUNT","JUNCTIONTYPE","SDOT_COLCODE","WEATHER","ROADCOND","LIGHTCOND","ST_COLCODE","HITPARKEDCAR"]]
accidents_df.head()
----


+*Out[8]:*+
----
[cols=",,,,,,,,,,,,,,",options="header",]
|===
| |SEVERITYCODE |ADDRTYPE |COLLISIONTYPE |PERSONCOUNT |PEDCOUNT
|PEDCYLCOUNT |VEHCOUNT |JUNCTIONTYPE |SDOT_COLCODE |WEATHER |ROADCOND
|LIGHTCOND |ST_COLCODE |HITPARKEDCAR
|0 |2 |Intersection |Angles |2 |0 |0 |2 |At Intersection (intersection
related) |11 |Overcast |Wet |Daylight |10 |N

|1 |1 |Block |Sideswipe |2 |0 |0 |2 |Mid-Block (not related to
intersection) |16 |Raining |Wet |Dark - Street Lights On |11 |N

|2 |1 |Block |Parked Car |4 |0 |0 |3 |Mid-Block (not related to
intersection) |14 |Overcast |Dry |Daylight |32 |N

|3 |1 |Block |Other |3 |0 |0 |3 |Mid-Block (not related to intersection)
|11 |Clear |Dry |Daylight |23 |N

|4 |2 |Intersection |Angles |2 |0 |0 |2 |At Intersection (intersection
related) |11 |Raining |Wet |Daylight |10 |N
|===
----


+*In[9]:*+
[source, ipython3]
----
missing_data = accidents_df.isnull()
for column in missing_data.columns.values.tolist():
    print(column)
    print (missing_data[column].value_counts())
    print("")    
    # Probably best to delete all rows with missing data as there are already a large number of entries
----


+*Out[9]:*+
----
SEVERITYCODE
False    194673
Name: SEVERITYCODE, dtype: int64

ADDRTYPE
False    192747
True       1926
Name: ADDRTYPE, dtype: int64

COLLISIONTYPE
False    189769
True       4904
Name: COLLISIONTYPE, dtype: int64

PERSONCOUNT
False    194673
Name: PERSONCOUNT, dtype: int64

PEDCOUNT
False    194673
Name: PEDCOUNT, dtype: int64

PEDCYLCOUNT
False    194673
Name: PEDCYLCOUNT, dtype: int64

VEHCOUNT
False    194673
Name: VEHCOUNT, dtype: int64

JUNCTIONTYPE
False    188344
True       6329
Name: JUNCTIONTYPE, dtype: int64

SDOT_COLCODE
False    194673
Name: SDOT_COLCODE, dtype: int64

WEATHER
False    189592
True       5081
Name: WEATHER, dtype: int64

ROADCOND
False    189661
True       5012
Name: ROADCOND, dtype: int64

LIGHTCOND
False    189503
True       5170
Name: LIGHTCOND, dtype: int64

ST_COLCODE
False    194655
True         18
Name: ST_COLCODE, dtype: int64

HITPARKEDCAR
False    194673
Name: HITPARKEDCAR, dtype: int64

----


+*In[10]:*+
[source, ipython3]
----
accidents_df.dropna(axis=0, inplace=True)
----


+*Out[10]:*+
----
/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  """Entry point for launching an IPython kernel.
----


+*In[11]:*+
[source, ipython3]
----
#Check to make sure there are no missing values in the dataframe

missing_data = accidents_df.isnull()
for column in missing_data.columns.values.tolist():
    print(column)
    print (missing_data[column].value_counts())
    print("")    
----


+*Out[11]:*+
----
SEVERITYCODE
False    182895
Name: SEVERITYCODE, dtype: int64

ADDRTYPE
False    182895
Name: ADDRTYPE, dtype: int64

COLLISIONTYPE
False    182895
Name: COLLISIONTYPE, dtype: int64

PERSONCOUNT
False    182895
Name: PERSONCOUNT, dtype: int64

PEDCOUNT
False    182895
Name: PEDCOUNT, dtype: int64

PEDCYLCOUNT
False    182895
Name: PEDCYLCOUNT, dtype: int64

VEHCOUNT
False    182895
Name: VEHCOUNT, dtype: int64

JUNCTIONTYPE
False    182895
Name: JUNCTIONTYPE, dtype: int64

SDOT_COLCODE
False    182895
Name: SDOT_COLCODE, dtype: int64

WEATHER
False    182895
Name: WEATHER, dtype: int64

ROADCOND
False    182895
Name: ROADCOND, dtype: int64

LIGHTCOND
False    182895
Name: LIGHTCOND, dtype: int64

ST_COLCODE
False    182895
Name: ST_COLCODE, dtype: int64

HITPARKEDCAR
False    182895
Name: HITPARKEDCAR, dtype: int64

----


+*In[12]:*+
[source, ipython3]
----
# checking there are enough entries of each type for confidence
accidents_df['ADDRTYPE'].value_counts()
----


+*Out[12]:*+
----Block           119362
Intersection     63298
Alley              235
Name: ADDRTYPE, dtype: int64----


+*In[13]:*+
[source, ipython3]
----
accidents_df.groupby(['ADDRTYPE'])['SEVERITYCODE'].value_counts(normalize=True)
# choose feature with >0.8 proportion for either severity code
----


+*Out[13]:*+
----ADDRTYPE      SEVERITYCODE
Alley         1               0.876596
              2               0.123404
Block         1               0.754930
              2               0.245070
Intersection  1               0.568012
              2               0.431988
Name: SEVERITYCODE, dtype: float64----


+*In[14]:*+
[source, ipython3]
----
Feature = accidents_df[['ADDRTYPE']]
Feature = pd.concat([Feature, pd.get_dummies(accidents_df['ADDRTYPE'])], axis=1) #make classes of 'ADDRTYPE' a feature
Feature.drop(['ADDRTYPE'], axis = 1,inplace=True)
Feature.drop(['Block'], axis = 1,inplace=True)
Feature.drop(['Intersection'], axis = 1,inplace=True) #Drop all features where proportion for a severity code is <0.8
Feature.head()

----


+*Out[14]:*+
----
[cols=",",options="header",]
|===
| |Alley
|0 |0
|1 |0
|2 |0
|3 |0
|4 |0
|===
----


+*In[15]:*+
[source, ipython3]
----
# checking there are enough entries of each type for confidence
accidents_df['COLLISIONTYPE'].value_counts()
----


+*Out[15]:*+
----Parked Car    43119
Angles        34453
Rear Ended    33641
Other         22960
Sideswipe     18285
Left Turn     13637
Pedestrian     6513
Cycles         5362
Right Turn     2929
Head On        1996
Name: COLLISIONTYPE, dtype: int64----


+*In[16]:*+
[source, ipython3]
----
accidents_df.groupby(['COLLISIONTYPE'])['SEVERITYCODE'].value_counts(normalize=True)
----


+*Out[16]:*+
----COLLISIONTYPE  SEVERITYCODE
Angles         1               0.606101
               2               0.393899
Cycles         2               0.877098
               1               0.122902
Head On        1               0.566132
               2               0.433868
Left Turn      1               0.604312
               2               0.395688
Other          1               0.738371
               2               0.261629
Parked Car     1               0.938960
               2               0.061040
Pedestrian     2               0.898511
               1               0.101489
Rear Ended     1               0.568205
               2               0.431795
Right Turn     1               0.793786
               2               0.206214
Sideswipe      1               0.865026
               2               0.134974
Name: SEVERITYCODE, dtype: float64----


+*In[17]:*+
[source, ipython3]
----
Feature = pd.concat([Feature, pd.get_dummies(accidents_df['COLLISIONTYPE'])], axis=1)

Feature.drop(['Angles'], axis = 1,inplace=True)
Feature.drop(['Head On'], axis = 1,inplace=True)
Feature.drop(['Left Turn'], axis = 1,inplace=True)
Feature.drop(['Other'], axis = 1,inplace=True)
Feature.drop(['Rear Ended'], axis = 1,inplace=True)           
Feature.drop(['Right Turn'], axis = 1,inplace=True)       

Feature.head()
# Applied same principals as before
----


+*Out[17]:*+
----
[cols=",,,,,",options="header",]
|===
| |Alley |Cycles |Parked Car |Pedestrian |Sideswipe
|0 |0 |0 |0 |0 |0
|1 |0 |0 |0 |0 |1
|2 |0 |0 |1 |0 |0
|3 |0 |0 |0 |0 |0
|4 |0 |0 |0 |0 |0
|===
----


+*In[18]:*+
[source, ipython3]
----
PersonCountValue = accidents_df.groupby(['PERSONCOUNT'])['SEVERITYCODE'].value_counts(normalize=True) #.to_frame()
# PersonCountValue.rename(columns={'SEVERITYCODE':'Value_Counts'}, inplace=True)
PersonCountValue = PersonCountValue.reset_index(name = 'Value_Counts')
# not sure what "0" personcount signifies. 0 other than the primary vehicle involved?~
----


+*In[19]:*+
[source, ipython3]
----
# creates dataframe from "PersonCountValue" showing values where "SEVERITYCODE==2"
PCV = PersonCountValue[PersonCountValue['SEVERITYCODE']==2] 
PCV
----


+*Out[19]:*+
----
[cols=",,,",options="header",]
|===
| |PERSONCOUNT |SEVERITYCODE |Value_Counts
|1 |0 |2 |0.322833
|3 |1 |2 |0.262731
|5 |2 |2 |0.255357
|7 |3 |2 |0.380357
|9 |4 |2 |0.431004
|11 |5 |2 |0.451307
|12 |6 |2 |0.502606
|14 |7 |2 |0.564674
|16 |8 |2 |0.534840
|18 |9 |2 |0.600939
|20 |10 |2 |0.582677
|22 |11 |2 |0.589286
|24 |12 |2 |0.606061
|26 |13 |2 |0.571429
|29 |14 |2 |0.368421
|30 |15 |2 |0.636364
|32 |16 |2 |0.625000
|34 |17 |2 |0.727273
|37 |18 |2 |0.166667
|39 |19 |2 |0.400000
|41 |20 |2 |0.166667
|44 |22 |2 |0.500000
|46 |23 |2 |0.500000
|48 |24 |2 |0.500000
|50 |25 |2 |0.166667
|53 |27 |2 |0.333333
|55 |28 |2 |0.333333
|57 |29 |2 |0.333333
|59 |30 |2 |0.500000
|62 |32 |2 |0.333333
|63 |34 |2 |0.666667
|68 |37 |2 |0.333333
|69 |39 |2 |1.000000
|74 |48 |2 |1.000000
|76 |54 |2 |1.000000
|78 |81 |2 |1.000000
|===
----


+*In[20]:*+
[source, ipython3]
----
# creating scatter plot 

x = PCV['PERSONCOUNT']
y = PCV['Value_Counts']


plt.scatter(x,y)
plt.title('Scatter plot of Person Count vs. Severity Code')
plt.xlabel('Person Count')
plt.ylabel('Severity Code')
# Not particularly useful for the model as a feature based on the wide range and randomness of value proportions
----


+*Out[20]:*+
----Text(0, 0.5, 'Severity Code')
![png](output_25_1.png)
----


+*In[21]:*+
[source, ipython3]
----
accidents_df['PEDCOUNT'].value_counts()
----


+*Out[21]:*+
----0    176053
1      6589
2       225
3        22
4         4
6         1
5         1
Name: PEDCOUNT, dtype: int64----


+*In[22]:*+
[source, ipython3]
----
accidents_df.groupby(['PEDCOUNT'])['SEVERITYCODE'].value_counts(normalize=True)
# Could transform this to a binary feature (0 or more than 0 for PEDCOUNT) since distribution is similar for all values above 0
----


+*Out[22]:*+
----PEDCOUNT  SEVERITYCODE
0         1               0.713325
          2               0.286675
1         2               0.898771
          1               0.101229
2         2               0.915556
          1               0.084444
3         2               0.954545
          1               0.045455
4         2               1.000000
5         2               1.000000
6         2               1.000000
Name: SEVERITYCODE, dtype: float64----


+*In[23]:*+
[source, ipython3]
----
Feature['PEDCOUNT>0'] = accidents_df['PEDCOUNT'].apply(lambda x: 1 if (x>0)  else 0)
Feature.head()
# Creates a binary feature for PEDCOUNT being either =0(0) or >0(1)
----


+*Out[23]:*+
----
[cols=",,,,,,",options="header",]
|===
| |Alley |Cycles |Parked Car |Pedestrian |Sideswipe |PEDCOUNT>0
|0 |0 |0 |0 |0 |0 |0
|1 |0 |0 |0 |0 |1 |0
|2 |0 |0 |1 |0 |0 |0
|3 |0 |0 |0 |0 |0 |0
|4 |0 |0 |0 |0 |0 |0
|===
----


+*In[24]:*+
[source, ipython3]
----
accidents_df['PEDCYLCOUNT'].value_counts()
----


+*Out[24]:*+
----0    177480
1      5374
2        41
Name: PEDCYLCOUNT, dtype: int64----


+*In[25]:*+
[source, ipython3]
----
accidents_df.groupby(['PEDCYLCOUNT'])['SEVERITYCODE'].value_counts(normalize=True)
# Could transform this to a binary feature (0 or more than 0 for PEDCYLCOUNT) since distribution is similar for all values above 0
----


+*Out[25]:*+
----PEDCYLCOUNT  SEVERITYCODE
0            1               0.707719
             2               0.292281
1            2               0.876442
             1               0.123558
2            2               1.000000
Name: SEVERITYCODE, dtype: float64----


+*In[26]:*+
[source, ipython3]
----
Feature['PEDCYLCOUNT>0'] = accidents_df['PEDCYLCOUNT'].apply(lambda x: 1 if (x>0)  else 0)
Feature.head()
# Creates a binary feature for PEDCYLCOUNT being either =0(0) or >0(1)
----


+*Out[26]:*+
----
[cols=",,,,,,,",options="header",]
|===
| |Alley |Cycles |Parked Car |Pedestrian |Sideswipe |PEDCOUNT>0
|PEDCYLCOUNT>0
|0 |0 |0 |0 |0 |0 |0 |0

|1 |0 |0 |0 |0 |1 |0 |0

|2 |0 |0 |1 |0 |0 |0 |0

|3 |0 |0 |0 |0 |0 |0 |0

|4 |0 |0 |0 |0 |0 |0 |0
|===
----


+*In[27]:*+
[source, ipython3]
----
accidents_df['VEHCOUNT'].value_counts()
----


+*Out[27]:*+
----2     141647
1      25029
3      12869
4       2407
5        526
0        195
6        144
7         45
8         15
9          9
11         6
10         2
12         1
Name: VEHCOUNT, dtype: int64----


+*In[28]:*+
[source, ipython3]
----
accidents_df.groupby(['VEHCOUNT'])['SEVERITYCODE'].value_counts(normalize=True)
# For VEHCOUNT=0, the classification accuracy would be high however the proportion =0 is very low
# VEHCOUNT>0 is quite random therefore bearing these 2 points in mind, VEHCOUNT will be left from the model
----


+*Out[28]:*+
----VEHCOUNT  SEVERITYCODE
0         2               0.984615
          1               0.015385
1         2               0.555076
          1               0.444924
2         1               0.748156
          2               0.251844
3         1               0.577512
          2               0.422488
4         1               0.554632
          2               0.445368
5         1               0.503802
          2               0.496198
6         1               0.590278
          2               0.409722
7         1               0.511111
          2               0.488889
8         1               0.666667
          2               0.333333
9         2               0.666667
          1               0.333333
10        2               1.000000
11        1               0.500000
          2               0.500000
12        1               1.000000
Name: SEVERITYCODE, dtype: float64----


+*In[29]:*+
[source, ipython3]
----
accidents_df['JUNCTIONTYPE'].value_counts()
----


+*Out[29]:*+
----Mid-Block (not related to intersection)              86609
At Intersection (intersection related)               61206
Mid-Block (but intersection related)                 22341
Driveway Junction                                    10519
At Intersection (but not related to intersection)     2055
Ramp Junction                                          160
Unknown                                                  5
Name: JUNCTIONTYPE, dtype: int64----


+*In[30]:*+
[source, ipython3]
----
accidents_df.groupby(['JUNCTIONTYPE'])['SEVERITYCODE'].value_counts(normalize=True)
# 'Unknown' is the only class which has a severity code with >0.8 porportion 
# therefore 'JUNCTIONTYPE' will not be used in the model
----


+*Out[30]:*+
----JUNCTIONTYPE                                       SEVERITYCODE
At Intersection (but not related to intersection)  1               0.700243
                                                   2               0.299757
At Intersection (intersection related)             1               0.563474
                                                   2               0.436526
Driveway Junction                                  1               0.696264
                                                   2               0.303736
Mid-Block (but intersection related)               1               0.678260
                                                   2               0.321740
Mid-Block (not related to intersection)            1               0.782274
                                                   2               0.217726
Ramp Junction                                      1               0.687500
                                                   2               0.312500
Unknown                                            1               0.800000
                                                   2               0.200000
Name: SEVERITYCODE, dtype: float64----


+*In[31]:*+
[source, ipython3]
----
accidents_df.groupby(['SDOT_COLCODE'])['SEVERITYCODE'].value_counts(normalize=True)
# Possibly too many different categories for a good model
----


+*Out[31]:*+
----SDOT_COLCODE  SEVERITYCODE
0             1               0.908068
              2               0.091932
11            1               0.711601
              2               0.288399
12            1               0.980292
                                ...   
66            1               0.043478
68            2               0.750000
              1               0.250000
69            2               0.985075
              1               0.014925
Name: SEVERITYCODE, Length: 73, dtype: float64----


+*In[32]:*+
[source, ipython3]
----
accidents_df['SDOT_COLCODE'].value_counts()
# too many different codes with wide variety of value counts to be useful to the model
----


+*Out[32]:*+
----11    83024
14    52486
16     9776
28     8699
24     6368
13     5614
26     4580
0      3111
18     3022
15     1567
12     1370
51     1288
29      472
21      180
56      177
27      160
54      134
23      122
48      106
31      103
25      101
34       92
64       74
69       67
33       53
55       50
66       23
22       16
32       12
53        9
44        8
61        7
35        6
68        4
36        4
58        4
46        3
52        2
47        1
Name: SDOT_COLCODE, dtype: int64----


+*In[33]:*+
[source, ipython3]
----
accidents_df.groupby(['WEATHER'])['SEVERITYCODE'].value_counts(normalize=True)
----


+*Out[33]:*+
----WEATHER                   SEVERITYCODE
Blowing Sand/Dirt         1               0.734694
                          2               0.265306
Clear                     1               0.673727
                          2               0.326273
Fog/Smog/Smoke            1               0.665468
                          2               0.334532
Other                     1               0.847185
                          2               0.152815
Overcast                  1               0.681014
                          2               0.318986
Partly Cloudy             2               0.600000
                          1               0.400000
Raining                   1               0.660468
                          2               0.339532
Severe Crosswind          1               0.720000
                          2               0.280000
Sleet/Hail/Freezing Rain  1               0.758929
                          2               0.241071
Snowing                   1               0.810443
                          2               0.189557
Unknown                   1               0.933746
                          2               0.066254
Name: SEVERITYCODE, dtype: float64----


+*In[34]:*+
[source, ipython3]
----
accidents_df['WEATHER'].value_counts()
----


+*Out[34]:*+
----Clear                       109059
Raining                      32642
Overcast                     27183
Unknown                      11637
Snowing                        881
Other                          746
Fog/Smog/Smoke                 556
Sleet/Hail/Freezing Rain       112
Blowing Sand/Dirt               49
Severe Crosswind                25
Partly Cloudy                    5
Name: WEATHER, dtype: int64----


+*In[35]:*+
[source, ipython3]
----
Feature = pd.concat([Feature, pd.get_dummies(accidents_df['WEATHER'])], axis=1)

Feature.drop(['Clear'], axis = 1,inplace=True)
Feature.drop(['Blowing Sand/Dirt'], axis = 1,inplace=True)
Feature.drop(['Fog/Smog/Smoke'], axis = 1,inplace=True)
Feature.drop(['Other'], axis = 1,inplace=True)
Feature.drop(['Overcast'], axis = 1,inplace=True)                                                          
Feature.drop(['Partly Cloudy'], axis = 1,inplace=True)     
Feature.drop(['Raining'], axis = 1,inplace=True)
Feature.drop(['Severe Crosswind'], axis = 1,inplace=True)                                                          
Feature.drop(['Sleet/Hail/Freezing Rain'], axis = 1,inplace=True) 
Feature.drop(['Unknown'], axis = 1,inplace=True)

Feature.head()
# Applied same principals as before
----


+*Out[35]:*+
----
[cols=",,,,,,,,",options="header",]
|===
| |Alley |Cycles |Parked Car |Pedestrian |Sideswipe |PEDCOUNT>0
|PEDCYLCOUNT>0 |Snowing
|0 |0 |0 |0 |0 |0 |0 |0 |0

|1 |0 |0 |0 |0 |1 |0 |0 |0

|2 |0 |0 |1 |0 |0 |0 |0 |0

|3 |0 |0 |0 |0 |0 |0 |0 |0

|4 |0 |0 |0 |0 |0 |0 |0 |0
|===
----


+*In[36]:*+
[source, ipython3]
----
accidents_df.groupby(['ROADCOND'])['SEVERITYCODE'].value_counts(normalize=True)
----


+*Out[36]:*+
----ROADCOND        SEVERITYCODE
Dry             1               0.674678
                2               0.325322
Ice             1               0.773152
                2               0.226848
Oil             1               0.600000
                2               0.400000
Other           1               0.658537
                2               0.341463
Sand/Mud/Dirt   1               0.671642
                2               0.328358
Snow/Slush      1               0.831288
                2               0.168712
Standing Water  1               0.731481
                2               0.268519
Unknown         1               0.938623
                2               0.061377
Wet             1               0.665382
                2               0.334618
Name: SEVERITYCODE, dtype: float64----


+*In[37]:*+
[source, ipython3]
----
accidents_df['ROADCOND'].value_counts()
----


+*Out[37]:*+
----Dry               122153
Wet                46710
Unknown            11519
Ice                 1177
Snow/Slush           978
Other                123
Standing Water       108
Sand/Mud/Dirt         67
Oil                   60
Name: ROADCOND, dtype: int64----


+*In[38]:*+
[source, ipython3]
----
Feature = pd.concat([Feature, pd.get_dummies(accidents_df['ROADCOND'])], axis=1)

Feature.drop(['Snowing'], axis = 1,inplace=True)
Feature.drop(['Ice'], axis = 1,inplace=True)
Feature.drop(['Oil'], axis = 1,inplace=True)
Feature.drop(['Other'], axis = 1,inplace=True)
Feature.drop(['Sand/Mud/Dirt'], axis = 1,inplace=True)                                                          
Feature.drop(['Standing Water'], axis = 1,inplace=True)     
Feature.drop(['Unknown'], axis = 1,inplace=True)
Feature.drop(['Wet'], axis = 1,inplace=True)     
Feature.drop(['Dry'], axis = 1,inplace=True) 

Feature.head()
# Applied same principals as before
----


+*Out[38]:*+
----
[cols=",,,,,,,,",options="header",]
|===
| |Alley |Cycles |Parked Car |Pedestrian |Sideswipe |PEDCOUNT>0
|PEDCYLCOUNT>0 |Snow/Slush
|0 |0 |0 |0 |0 |0 |0 |0 |0

|1 |0 |0 |0 |0 |1 |0 |0 |0

|2 |0 |0 |1 |0 |0 |0 |0 |0

|3 |0 |0 |0 |0 |0 |0 |0 |0

|4 |0 |0 |0 |0 |0 |0 |0 |0
|===
----


+*In[39]:*+
[source, ipython3]
----
accidents_df.groupby(['LIGHTCOND'])['SEVERITYCODE'].value_counts(normalize=True)
# No severity code proportions >0.8 so won't use 'LIGHTCOND' in the models
----


+*Out[39]:*+
----LIGHTCOND                 SEVERITYCODE
Dark - No Street Lights   1               0.775496
                          2               0.224504
Dark - Street Lights Off  1               0.729473
                          2               0.270527
Dark - Street Lights On   1               0.698172
                          2               0.301828
Dark - Unknown Lighting   1               0.636364
                          2               0.363636
Dawn                      1               0.666123
                          2               0.333877
Daylight                  1               0.663941
                          2               0.336059
Dusk                      1               0.666262
                          2               0.333738
Other                     1               0.752381
                          2               0.247619
Unknown                   1               0.944870
                          2               0.055130
Name: SEVERITYCODE, dtype: float64----


+*In[40]:*+
[source, ipython3]
----
accidents_df.groupby(['ST_COLCODE'])['SEVERITYCODE'].value_counts(normalize=True)
----


+*Out[40]:*+
----ST_COLCODE  SEVERITYCODE
0           2               0.910023
            1               0.089977
1           2               0.903646
            1               0.096354
2           2               0.930926
                              ...   
84          2               0.333333
85          1               1.000000
87          2               1.000000
88          1               0.625000
            2               0.375000
Name: SEVERITYCODE, Length: 215, dtype: float64----


+*In[41]:*+
[source, ipython3]
----
accidents_df['ST_COLCODE'].value_counts()
# Too many different categories to be useful to the models
----


+*Out[41]:*+
----32    24094
10    23248
14    16648
32    15525
10    11205
      ...  
54        1
43        1
87        1
43        1
85        1
Name: ST_COLCODE, Length: 114, dtype: int64----


+*In[42]:*+
[source, ipython3]
----
accidents_df.groupby(['HITPARKEDCAR'])['SEVERITYCODE'].value_counts(normalize=True)
# Probably too many categories to fit to a good model
----


+*Out[42]:*+
----HITPARKEDCAR  SEVERITYCODE
N             1               0.682735
              2               0.317265
Y             1               0.928998
              2               0.071002
Name: SEVERITYCODE, dtype: float64----


+*In[43]:*+
[source, ipython3]
----
Feature = pd.concat([Feature, pd.get_dummies(accidents_df['HITPARKEDCAR'])], axis=1)

Feature.drop(['N'], axis = 1,inplace=True)

Feature.rename(columns={'Y':'Hit Parked Car - Y'}, inplace=True)

Feature.head()
----


+*Out[43]:*+
----
[cols=",,,,,,,,,",options="header",]
|===
| |Alley |Cycles |Parked Car |Pedestrian |Sideswipe |PEDCOUNT>0
|PEDCYLCOUNT>0 |Snow/Slush |Hit Parked Car - Y
|0 |0 |0 |0 |0 |0 |0 |0 |0 |0

|1 |0 |0 |0 |0 |1 |0 |0 |0 |0

|2 |0 |0 |1 |0 |0 |0 |0 |0 |0

|3 |0 |0 |0 |0 |0 |0 |0 |0 |0

|4 |0 |0 |0 |0 |0 |0 |0 |0 |0
|===
----


+*In[44]:*+
[source, ipython3]
----
# Create separate frame for target data and categorical data
y_data = accidents_df['SEVERITYCODE']
x_data = Feature
----


+*In[45]:*+
[source, ipython3]
----
from sklearn.model_selection import train_test_split


# function "train_test_split" randomly separates data into training and test data
x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.15, random_state=1)


print("number of test samples :", x_test.shape[0])
print("number of training samples:",x_train.shape[0])

----


+*Out[45]:*+
----
number of test samples : 27435
number of training samples: 155460
----


+*In[46]:*+
[source, ipython3]
----
from sklearn.linear_model import LinearRegression

# create linear regression object
lre=LinearRegression()
----


+*In[47]:*+
[source, ipython3]
----
# Fit model using training data
lre.fit(x_train, y_train)
----


+*Out[47]:*+
----LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
         normalize=False)----


+*In[48]:*+
[source, ipython3]
----
# R^2 for test data
lre.score(x_test,y_test)
----


+*Out[48]:*+
----0.19844532825308858----


+*In[49]:*+
[source, ipython3]
----
# R^2 for training data
lre.score(x_train,y_train)
----


+*Out[49]:*+
----0.19860234983789082----


+*In[50]:*+
[source, ipython3]
----
# Prediction using training data

yhat_train = lre.predict(x_train)
yhat_train[0:5]
----


+*Out[50]:*+
----array([1.86855583, 1.13236559, 1.06256926, 1.37328322, 1.37328322])----


+*In[51]:*+
[source, ipython3]
----
# Prediction using test data

yhat_test = lre.predict(x_test)
yhat_test[0:5]
----


+*Out[51]:*+
----array([1.37328322, 1.37328322, 1.89961186, 1.13236559, 1.37328322])----


+*In[52]:*+
[source, ipython3]
----
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns
----


+*In[53]:*+
[source, ipython3]
----
def DistributionPlot(RedFunction, BlueFunction, RedName, BlueName, Title):
    width = 12
    height = 10
    plt.figure(figsize=(width, height))

    ax1 = sns.distplot(RedFunction, hist=False, color="r", label=RedName)
    ax2 = sns.distplot(BlueFunction, hist=False, color="b", label=BlueName, ax=ax1)

    plt.title(Title)
    plt.xlabel('Severity')
    plt.ylabel('Proportion of Accidents')

    plt.show()
    plt.close()
----


+*In[54]:*+
[source, ipython3]
----
# Distribution of predicted values of the training data
Title = 'Distribution  Plot of  Predicted Value Using Training Data vs Training Data Distribution'
DistributionPlot(y_train, yhat_train, "Actual Values (Train)", "Predicted Values (Train)", Title)
----


+*Out[54]:*+
----
![png](output_59_0.png)
----


+*In[55]:*+
[source, ipython3]
----
Title='Distribution  Plot of  Predicted Value Using Test Data vs Data Distribution of Test Data'
DistributionPlot(y_test,yhat_test,"Actual Values (Test)","Predicted Values (Test)",Title)
----


+*Out[55]:*+
----
![png](output_60_0.png)
----


+*In[ ]:*+
[source, ipython3]
----
from sklearn.preprocessing import PolynomialFeatures

Rsqu_test = []

order = [1, 2, 3, 4]
for n in order:
    pr = PolynomialFeatures(degree=n)
    
    x_train_pr = pr.fit_transform(x_train)
    
    x_test_pr = pr.fit_transform(x_test)    
    
    lre.fit(x_train_pr, y_train)
    
    Rsqu_test.append(lre.score(x_test_pr, y_test))

plt.plot(order, Rsqu_test)
plt.xlabel('order')
plt.ylabel('R^2')
plt.title('R^2 Using Test Data')
    
----


+*In[55]:*+
[source, ipython3]
----
# Better to use a classification model for this project. First will create a numpy array

X = Feature.values
X[0:5]
----


+*Out[55]:*+
----array([[0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 1, 0, 0, 0, 0],
       [0, 0, 1, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0]])----


+*In[56]:*+
[source, ipython3]
----
Y = y_data.values
Y[0:5]
----


+*Out[56]:*+
----array([2, 1, 1, 1, 2])----


+*In[57]:*+
[source, ipython3]
----
# Data Standardization give data zero mean and unit variance, it is good practice, especially for algorithms such as KNN which is based on distance of cases

from sklearn import preprocessing
X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))
X[0:5]
----


+*Out[57]:*+
----
/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.
  warnings.warn(msg, DataConversionWarning)
array([[-0.03586842, -0.17378963, -0.55541555, -0.19216018, -0.33328777,
        -0.19713776, -0.17467249, -0.07332174, -0.17919181],
       [-0.03586842, -0.17378963, -0.55541555, -0.19216018,  3.00041014,
        -0.19713776, -0.17467249, -0.07332174, -0.17919181],
       [-0.03586842, -0.17378963,  1.80045373, -0.19216018, -0.33328777,
        -0.19713776, -0.17467249, -0.07332174, -0.17919181],
       [-0.03586842, -0.17378963, -0.55541555, -0.19216018, -0.33328777,
        -0.19713776, -0.17467249, -0.07332174, -0.17919181],
       [-0.03586842, -0.17378963, -0.55541555, -0.19216018, -0.33328777,
        -0.19713776, -0.17467249, -0.07332174, -0.17919181]])----


+*In[58]:*+
[source, ipython3]
----

X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size=0.2, random_state=4)
print ('Train set:', X_train.shape,  y_train.shape)
print ('Test set:', X_test.shape,  y_test.shape)
----


+*Out[58]:*+
----
Train set: (146316, 9) (146316,)
Test set: (36579, 9) (36579,)
----


+*In[59]:*+
[source, ipython3]
----
from sklearn.neighbors import KNeighborsClassifier
k = 4
#Train Model and Predict  
neigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)
neigh
----


+*Out[59]:*+
----KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=None, n_neighbors=4, p=2,
           weights='uniform')----


+*In[58]:*+
[source, ipython3]
----
#Use model to predict the test set
yhat = neigh.predict(X_test)
yhat[0:5]
----


+*Out[58]:*+
----array([2, 1, 1, 1, 1])----


+*In[64]:*+
[source, ipython3]
----
#n multilabel classification, accuracy classification score is a function that computes subset accuracy. This function is equal to the jaccard_similarity_score function. Essentially, it calculates how closely the actual labels and predicted labels are matched in the test set.

from sklearn import metrics
print("Train set Accuracy: ", metrics.accuracy_score(y_train, neigh.predict(X_train)))
print("Test set Accuracy: ", metrics.accuracy_score(y_test, yhat))
----


+*Out[64]:*+
----
Train set Accuracy:  0.7431586429372045
Test set Accuracy:  0.7370075726509746
----


+*In[60]:*+
[source, ipython3]
----
# Try different values of K to create model with best prediction accuracy

Ks = 10
mean_acc = np.zeros((Ks-1))
std_acc = np.zeros((Ks-1))
ConfustionMx = [];
for n in range(1,Ks):
    
    #Train Model and Predict  
    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)
    yhat=neigh.predict(X_test)
    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)

    
    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])

mean_acc
----


+*Out[60]:*+
----array([0.70857596, 0.71065365, 0.73692556, 0.73700757, 0.59279915,
       0.59279915, 0.59277181, 0.59277181, 0.59274447])----


+*In[62]:*+
[source, ipython3]
----
plt.plot(range(1,Ks),mean_acc,'g')
plt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)
plt.legend(('Accuracy ', '+/- 3xstd'))
plt.ylabel('Accuracy ')
plt.xlabel('Number of Neighbours (K)')
plt.tight_layout()
plt.show()
----


+*Out[62]:*+
----
![png](output_70_0.png)
----


+*In[68]:*+
[source, ipython3]
----
# Now we will create a tree diagram to assess it's viability as a model

from sklearn.tree import DecisionTreeClassifier

drugTree = DecisionTreeClassifier(criterion="entropy", max_depth = 9)
drugTree # it shows the default parameters
----


+*Out[68]:*+
----DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=9,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')----


+*In[69]:*+
[source, ipython3]
----
drugTree.fit(X_train,y_train)
----


+*Out[69]:*+
----DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=9,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')----


+*In[70]:*+
[source, ipython3]
----
predTree = drugTree.predict(X_test)
print (predTree [0:5])
print (y_test [0:5])
----


+*Out[70]:*+
----
[2 1 1 1 1]
[2 1 2 1 1]
----


+*In[71]:*+
[source, ipython3]
----
# Check accuracy of the model

print("DecisionTrees's Accuracy: ", metrics.accuracy_score(y_test, predTree))
----


+*Out[71]:*+
----
DecisionTrees's Accuracy:  0.7373629678230679
----


+*In[75]:*+
[source, ipython3]
----
# We will create another form of classification model using Logistic Regression & use a Confusion Matrix
# to assess the accuracy #

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix

LR = LogisticRegression(C=0.5, solver='liblinear').fit(X_train,y_train)
LR
----


+*Out[75]:*+
----LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',
          tol=0.0001, verbose=0, warm_start=False)----


+*In[76]:*+
[source, ipython3]
----
yhat = LR.predict(X_test)
yhat[0:5]
----


+*Out[76]:*+
----array([2, 1, 1, 1, 1])----


+*In[71]:*+
[source, ipython3]
----
# predict_proba returns estimates for all classes, ordered by the label of classes. So, the first column is the probability of class 1, P(Y=1|X),
# and second column is probability of class 0, P(Y=0|X) #

yhat_prob = LR.predict_proba(X_test)
yhat_prob[0:5]
----


+*Out[71]:*+
----array([[0.1 , 0.9 ],
       [0.63, 0.37],
       [0.63, 0.37],
       [0.63, 0.37],
       [0.94, 0.06]])----


+*In[77]:*+
[source, ipython3]
----
# We will use jaccard index for accuracy evaluation. we can define jaccard as the size of the intersection divided by the size of the union of two label sets
# If the entire set of predicted labels for a sample strictly match with the true set of labels, then the subset accuracy is 1.0; otherwise it is 0.0 #

from sklearn.metrics import jaccard_similarity_score
jaccard_similarity_score(y_test, yhat)
----


+*Out[77]:*+
----0.7372809535525848----


+*In[78]:*+
[source, ipython3]
----
# we will use a confusion matrix to determine the accuracy of the classifier.
# First we need to define the plotting function #

from sklearn.metrics import classification_report, confusion_matrix
import itertools
def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
print(confusion_matrix(y_test, yhat, labels=[2,1]))
----


+*Out[78]:*+
----
[[ 2106  9312]
 [  298 24863]]
----


+*In[74]:*+
[source, ipython3]
----
# Compute confusion matrix
cnf_matrix = confusion_matrix(y_test, yhat, labels=[2,1])
np.set_printoptions(precision=2)


# Plot non-normalized confusion matrix
plt.figure()
plot_confusion_matrix(cnf_matrix, classes=['severity=2','severity=1'],normalize= False,  title='Confusion matrix')
----


+*Out[74]:*+
----
Confusion matrix, without normalization
[[ 2106  9312]
 [  298 24863]]

![png](output_80_1.png)
----


+*In[68]:*+
[source, ipython3]
----

print (classification_report(y_test, yhat))
----


+*Out[68]:*+
----
              precision    recall  f1-score   support

           1       0.73      0.99      0.84     25161
           2       0.88      0.18      0.30     11418

   micro avg       0.74      0.74      0.74     36579
   macro avg       0.80      0.59      0.57     36579
weighted avg       0.77      0.74      0.67     36579

----


+*In[ ]:*+
[source, ipython3]
----

----
